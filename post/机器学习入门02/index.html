<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.86.1" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>机器学习入门02&nbsp;&ndash;&nbsp;Wei Chu</title><link rel="stylesheet" href="/css/core.min.746d4f5e0f69f8ca3fdabdfef6b99d63a9852de221102d14b47177e2a4e0fb979941c84b1ae5b6a490e592140624482e.css" integrity="sha384-dG1PXg9p&#43;Mo/2r3&#43;9rmdY6mFLeIhEC0UtHF34qTg&#43;5eZQchLGuW2pJDlkhQGJEgu"><body>
    <div class="base-body"><section id="header" class="site header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><img class="site logo" src="/images/logo.png" alt /><span class="site name">Wei Chu</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/categories/">Categories</a><a class="nav item" href="/tags/">Tags</a><a class="nav item" href="/about/">About</a><a class="nav item" href="https://gohugo.io/"target="_blank">Hugo</a></nav></div></span></div><div class="site slogan"><span class="title">醉后不知天在水 满船清梦压星河</span></div></section><div id="content"><section class="article header">
    <h1 class="article title">机器学习入门02</h1><p class="article date">Nov 30, 2021<span class="reading-time"> • 4 minutes to read</span></p></section><article class="article markdown-body"><p>来源：<a href="https://www.bilibili.com/video/BV1nt411r7tj?p=1"target="_blank">https://www.bilibili.com/video/BV1nt411r7tj?p=1</a></p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://github.com/ChuWeiEr/Luminary/raw/master/StudyPicture/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A802.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">机器学习day02</div>
</center>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">分类算法</span>

<span class="n">目标值</span><span class="err">：</span><span class="n">类别</span>

<span class="mi">1</span><span class="err">、</span><span class="n">sklearn转换器和预估器</span>
<span class="mi">2</span><span class="err">、</span><span class="n">KNN算法</span>
<span class="mi">3</span><span class="err">、</span><span class="n">模型选择与调优</span>
<span class="mi">4</span><span class="err">、</span><span class="n">朴素贝叶斯算法</span>
<span class="mi">5</span><span class="err">、</span><span class="n">决策树</span>
<span class="mi">6</span><span class="err">、</span><span class="n">随机森林</span>

<span class="mf">3.1</span> <span class="n">sklearn转换器和估计器</span>
    <span class="n">转换器</span>
    <span class="n">估计器</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span>
    <span class="mf">3.1.1</span> <span class="n">转换器</span> <span class="o">-</span> <span class="n">特征工程的父类</span>
        <span class="mi">1</span> <span class="n">实例化</span> <span class="p">(</span><span class="n">实例化的是一个转换器类</span><span class="p">(</span><span class="n">Transformer</span><span class="p">))</span>
        <span class="mi">2</span> <span class="n">调用fit_transform</span><span class="p">(</span><span class="n">对于文档建立分类词频矩阵</span><span class="err">，</span><span class="n">不能同时调用</span><span class="p">)</span>
        <span class="n">标准化</span><span class="err">：</span>
            <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
            <span class="n">fit_transform</span><span class="p">()</span>
                <span class="n">fit</span><span class="p">()</span>           <span class="n">计算</span> <span class="n">每一列的平均值</span><span class="err">、</span><span class="n">标准差</span>
                <span class="n">transform</span><span class="p">()</span>     <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std进行最终的转换</span>
    <span class="mf">3.1.2</span> <span class="n">估计器</span><span class="p">(</span><span class="n">sklearn机器学习算法的实现</span><span class="p">)</span>
        <span class="n">估计器</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span>
            <span class="mi">1</span> <span class="n">实例化一个estimator</span>
            <span class="mi">2</span> <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="n">计算</span>
                <span class="err">——</span> <span class="n">调用完毕</span><span class="err">，</span><span class="n">模型生成</span>
            <span class="mi">3</span> <span class="n">模型评估</span><span class="err">：</span>
                <span class="mi">1</span><span class="err">）</span><span class="n">直接比对真实值和预测值</span>
                    <span class="n">y_predict</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
                    <span class="n">y_test</span> <span class="o">==</span> <span class="n">y_predict</span>
                <span class="mi">2</span><span class="err">）</span><span class="n">计算准确率</span>
                    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="mf">3.2</span> <span class="n">K</span><span class="o">-</span><span class="n">近邻算法</span>
    <span class="mf">3.2.1</span> <span class="n">什么是K</span><span class="o">-</span><span class="n">近邻算法</span>
        <span class="n">KNN核心思想</span><span class="err">：</span>
            <span class="n">你的</span><span class="err">“</span><span class="n">邻居</span><span class="err">”</span><span class="n">来推断出你的类别</span>
        <span class="mi">1</span> <span class="n">K</span><span class="o">-</span><span class="n">近邻算法</span><span class="p">(</span><span class="n">KNN</span><span class="p">)</span><span class="n">原理</span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">容易受到异常点的影响</span>
            <span class="n">如何确定谁是邻居</span><span class="err">？</span>
            <span class="n">计算距离</span><span class="err">：</span>
                <span class="n">距离公式</span>
                    <span class="n">欧氏距离</span>
                    <span class="n">曼哈顿距离</span> <span class="n">绝对值距离</span>
                    <span class="n">明可夫斯基距离</span>
        <span class="mi">2</span> <span class="n">电影类型分析</span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span> <span class="n">爱情片</span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span> <span class="n">爱情片</span>
            <span class="err">……</span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">6</span> <span class="n">无法确定</span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">7</span> <span class="n">动作片</span>

            <span class="n">如果取的最近的电影数量不一样</span><span class="err">？</span><span class="n">会是什么结果</span><span class="err">？</span>
                <span class="n">k</span> <span class="n">值取得过小</span><span class="err">，</span><span class="n">容易受到异常点的影响</span>
                <span class="n">k</span> <span class="n">值取得过大</span><span class="err">，</span><span class="n">样本不均衡的影响</span>
            <span class="n">结合前面的约会对象数据</span><span class="err">，</span><span class="n">分析K</span><span class="o">-</span><span class="n">近邻算法需要做什么样的处理</span>
                <span class="n">无量纲化的处理</span>
                    <span class="n">标准化</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
            <span class="n">n_neighbors</span><span class="err">：</span><span class="n">k值</span>
        <span class="mf">3.2.3</span> <span class="n">案例1</span><span class="err">：</span><span class="n">鸢尾花种类预测</span>
            <span class="mi">1</span><span class="err">）</span><span class="n">获取数据</span>
            <span class="mi">2</span><span class="err">）</span><span class="n">数据集划分</span>
            <span class="mi">3</span><span class="err">）</span><span class="n">特征工程</span>
                <span class="n">标准化</span>
            <span class="mi">4</span><span class="err">）</span><span class="n">KNN预估器流程</span>
            <span class="mi">5</span><span class="err">）</span><span class="n">模型评估</span>
        <span class="mf">3.2.4</span> <span class="n">K</span><span class="o">-</span><span class="n">近邻总结</span>
            <span class="n">优点</span><span class="err">：</span><span class="n">简单</span><span class="err">，</span><span class="n">易于理解</span><span class="err">，</span><span class="n">易于实现</span><span class="err">，</span><span class="n">无需训练</span>
            <span class="n">缺点</span><span class="err">：</span>
                <span class="mi">1</span><span class="err">）</span><span class="n">必须指定K值</span><span class="err">，</span><span class="n">K值选择不当则分类精度不能保证</span>
                <span class="mi">2</span><span class="err">）</span><span class="n">懒惰算法</span><span class="err">，</span><span class="n">对测试样本分类时的计算量大</span><span class="err">，</span><span class="n">内存开销大</span>
            <span class="n">使用场景</span><span class="err">：</span><span class="n">小数据场景</span><span class="err">，</span><span class="n">几千</span><span class="err">～</span><span class="n">几万样本</span><span class="err">，</span><span class="n">具体场景具体业务去测试</span>
    <span class="mf">3.3</span> <span class="n">模型选择与调优</span>
        <span class="mf">3.3.1</span> <span class="n">什么是交叉验证</span><span class="p">(</span><span class="n">cross</span> <span class="n">validation</span><span class="p">)</span>
        <span class="mf">3.3.2</span> <span class="n">超参数搜索</span><span class="o">-</span><span class="n">网格搜索</span><span class="p">(</span><span class="n">Grid</span> <span class="n">Search</span><span class="p">)</span>
            <span class="n">k的取值</span>
                <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">]</span>
                <span class="n">暴力破解</span>
        <span class="mf">3.3.3</span> <span class="n">鸢尾花案例增加K值调优</span>
        <span class="mf">3.2.4</span> <span class="n">案例</span><span class="err">：</span><span class="n">预测facebook签到位置</span>
            <span class="n">流程分析</span><span class="err">：</span>
                <span class="mi">1</span><span class="err">）</span><span class="n">获取数据</span>
                <span class="mi">2</span><span class="err">）</span><span class="n">数据处理</span>
                <span class="n">目的</span><span class="err">：</span>
                    <span class="n">特征值</span> <span class="n">x</span>
                    <span class="n">目标值</span> <span class="n">y</span>
                    <span class="n">a</span><span class="o">.</span><span class="n">缩小数据范围</span>
                      <span class="mi">2</span> <span class="o">&lt;</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mf">2.5</span>
                      <span class="mf">1.0</span> <span class="o">&lt;</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="mf">1.5</span>
                    <span class="n">b</span><span class="o">.</span><span class="n">time</span> <span class="o">-&gt;</span> <span class="n">年月日时分秒</span>
                    <span class="n">c</span><span class="o">.</span><span class="n">过滤签到次数少的地点</span>
                    <span class="n">数据集划分</span>
                 <span class="mi">3</span><span class="err">）</span><span class="n">特征工程</span><span class="err">：</span><span class="n">标准化</span>
                 <span class="mi">4</span><span class="err">）</span><span class="n">KNN算法预估流程</span>
                 <span class="mi">5</span><span class="err">）</span><span class="n">模型选择与调优</span>
                 <span class="mi">6</span><span class="err">）</span><span class="n">模型评估</span>
 <span class="mf">3.4</span> <span class="n">朴素贝叶斯算法</span>
    <span class="mf">3.4.1</span> <span class="n">什么是朴素贝叶斯分类方法</span>
    <span class="mf">3.4.2</span> <span class="n">概率基础</span>
        <span class="mi">1</span> <span class="n">概率</span><span class="p">(</span><span class="n">Probability</span><span class="p">)</span><span class="n">定义</span>
        <span class="mf">3.4.3</span> <span class="n">联合概率</span><span class="err">、</span><span class="n">条件概率与相互独立</span>
            <span class="n">联合概率</span><span class="err">：</span><span class="n">包含多个条件</span><span class="err">，</span><span class="n">且所有条件同时成立的概率</span>
            <span class="n">P</span><span class="p">(</span><span class="n">程序员</span><span class="p">,</span> <span class="n">匀称</span><span class="p">)</span> <span class="n">P</span><span class="p">(</span><span class="n">程序员</span><span class="p">,</span> <span class="n">超重</span><span class="o">|</span><span class="n">喜欢</span><span class="p">)</span>
            <span class="n">P</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
            <span class="n">条件概率</span><span class="err">：</span><span class="n">就是事件A在另外一个事件B已经发生条件下的发生概率</span>
            <span class="n">P</span><span class="p">(</span><span class="n">程序员</span><span class="o">|</span><span class="n">喜欢</span><span class="p">)</span> <span class="n">P</span><span class="p">(</span><span class="n">程序员</span><span class="p">,</span> <span class="n">超重</span><span class="o">|</span><span class="n">喜欢</span><span class="p">)</span>
            <span class="n">P</span><span class="p">(</span><span class="n">A</span><span class="o">|</span><span class="n">B</span><span class="p">)</span>
            <span class="n">相互独立</span><span class="p">:</span>
                <span class="n">P</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span> <span class="o">=</span> <span class="n">P</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="n">P</span><span class="p">(</span><span class="n">B</span><span class="p">)</span> <span class="o">&lt;=&gt;</span> <span class="n">事件A与事件B相互独立</span>
        <span class="n">朴素</span><span class="err">？</span>
            <span class="n">假设</span><span class="err">：</span><span class="n">特征与特征之间是相互独立</span>
        <span class="n">朴素贝叶斯算法</span><span class="err">：</span>
            <span class="n">朴素</span> <span class="o">+</span> <span class="n">贝叶斯</span>
        <span class="n">应用场景</span><span class="err">：</span>
            <span class="n">文本分类</span>
            <span class="n">单词作为特征</span>
        <span class="n">拉普拉斯平滑系数</span>
    <span class="mf">3.4.6</span> <span class="n">案例</span><span class="err">：</span><span class="mi">20</span><span class="n">类新闻分类</span>
        <span class="mi">1</span><span class="err">）</span><span class="n">获取数据</span>
        <span class="mi">2</span><span class="err">）</span><span class="n">划分数据集</span>
        <span class="mi">3</span><span class="err">）</span><span class="n">特征工程</span>
            <span class="n">文本特征抽取</span>
        <span class="mi">4</span><span class="err">）</span><span class="n">朴素贝叶斯预估器流程</span>
        <span class="mi">5</span><span class="err">）</span><span class="n">模型评估</span>
    <span class="mf">3.4.7</span> <span class="n">朴素贝叶斯算法总结</span>
        <span class="n">优点</span><span class="err">：</span>
            <span class="n">对缺失数据不太敏感</span><span class="err">，</span><span class="n">算法也比较简单</span><span class="err">，</span><span class="n">常用于文本分类</span><span class="err">。</span>
            <span class="n">分类准确度高</span><span class="err">，</span><span class="n">速度快</span>
        <span class="n">缺点</span><span class="err">：</span>
            <span class="n">由于使用了样本属性独立性的假设</span><span class="err">，</span><span class="n">所以如果特征属性有关联时其效果不好</span>

            <span class="n">我爱北京天安门</span>
<span class="mf">3.5</span> <span class="n">决策树</span>
    <span class="mf">3.5.1</span> <span class="n">认识决策树</span>
        <span class="n">如何高效的进行决策</span><span class="err">？</span>
            <span class="n">特征的先后顺序</span>
    <span class="mf">3.5.2</span> <span class="n">决策树分类原理详解</span>
        <span class="n">已知</span> <span class="n">四个特征值</span> <span class="n">预测</span> <span class="n">是否贷款给某个人</span>
        <span class="n">先看房子</span><span class="err">，</span><span class="n">再工作</span> <span class="o">-&gt;</span> <span class="n">是否贷款</span> <span class="n">只看了两个特征</span>
        <span class="n">年龄</span><span class="err">，</span><span class="n">信贷情况</span><span class="err">，</span><span class="n">工作</span> <span class="n">看了三个特征</span>
    <span class="n">信息论基础</span>
        <span class="mi">1</span><span class="err">）</span><span class="n">信息</span>
            <span class="n">香农</span><span class="err">：</span><span class="n">消除随机不定性的东西</span>
            <span class="n">小明</span> <span class="n">年龄</span> <span class="err">“</span><span class="n">我今年18岁</span><span class="err">”</span> <span class="o">-</span> <span class="n">信息</span>
            <span class="n">小华</span> <span class="err">”</span><span class="n">小明明年19岁</span><span class="err">”</span> <span class="o">-</span> <span class="n">不是信息</span>
        <span class="mi">2</span><span class="err">）</span><span class="n">信息的衡量</span> <span class="o">-</span> <span class="n">信息量</span> <span class="o">-</span> <span class="n">信息熵</span>
            <span class="n">bit</span>
            <span class="n">g</span><span class="p">(</span><span class="n">D</span><span class="p">,</span><span class="n">A</span><span class="p">)</span> <span class="o">=</span> <span class="n">H</span><span class="p">(</span><span class="n">D</span><span class="p">)</span> <span class="o">-</span> <span class="n">条件熵H</span><span class="p">(</span><span class="n">D</span><span class="o">|</span><span class="n">A</span><span class="p">)</span>
        <span class="mi">4</span> <span class="n">决策树的划分依据之一</span><span class="o">------</span><span class="n">信息增益</span>
        <span class="n">没有免费的午餐</span>
    <span class="mf">3.5.5</span> <span class="n">决策树可视化</span>
    <span class="mf">3.5.6</span> <span class="n">决策树总结</span>
        <span class="n">优点</span><span class="err">：</span>
            <span class="n">可视化</span> <span class="o">-</span> <span class="n">可解释能力强</span>
        <span class="n">缺点</span><span class="err">：</span>
            <span class="n">容易产生过拟合</span>
    <span class="mf">3.5.4</span> <span class="n">案例</span><span class="err">：</span><span class="n">泰坦尼克号乘客生存预测</span>
        <span class="n">流程分析</span><span class="err">：</span>
            <span class="n">特征值</span> <span class="n">目标值</span>
            <span class="mi">1</span><span class="err">）</span><span class="n">获取数据</span>
            <span class="mi">2</span><span class="err">）</span><span class="n">数据处理</span>
                <span class="n">缺失值处理</span>
                <span class="n">特征值</span> <span class="o">-&gt;</span> <span class="n">字典类型</span>
            <span class="mi">3</span><span class="err">）</span><span class="n">准备好特征值</span> <span class="n">目标值</span>
            <span class="mi">4</span><span class="err">）</span><span class="n">划分数据集</span>
            <span class="mi">5</span><span class="err">）</span><span class="n">特征工程</span><span class="err">：</span><span class="n">字典特征抽取</span>
            <span class="mi">6</span><span class="err">）</span><span class="n">决策树预估器流程</span>
            <span class="mi">7</span><span class="err">）</span><span class="n">模型评估</span>
<span class="mf">3.6</span> <span class="n">集成学习方法之随机森林</span>
    <span class="mf">3.6.1</span> <span class="n">什么是集成学习方法</span>
    <span class="mf">3.6.2</span> <span class="n">什么是随机森林</span>
        <span class="n">随机</span>
        <span class="n">森林</span><span class="err">：</span><span class="n">包含多个决策树的分类器</span>
    <span class="mf">3.6.3</span> <span class="n">随机森林原理过程</span>
        <span class="n">训练集</span><span class="err">：</span>
        <span class="n">N个样本</span>
        <span class="n">特征值</span> <span class="n">目标值</span>
        <span class="n">M个特征</span>
        <span class="n">随机</span>
            <span class="n">两个随机</span>
                <span class="n">训练集随机</span> <span class="o">-</span> <span class="n">N个样本中随机有放回的抽样N个</span>
                    <span class="n">bootstrap</span> <span class="n">随机有放回抽样</span>
                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
                    <span class="n">新的树的训练集</span>
                    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
                <span class="n">特征随机</span> <span class="o">-</span> <span class="n">从M个特征中随机抽取m个特征</span>
                    <span class="n">M</span> <span class="o">&gt;&gt;</span> <span class="n">m</span>
                    <span class="n">降维</span>
    <span class="mf">3.6.6</span> <span class="n">总结</span>
          <span class="n">能够有效地运行在大数据集上</span><span class="err">，</span>
          <span class="n">处理具有高维特征的输入样本</span><span class="err">，</span><span class="n">而且不需要降维</span>          

</code></pre></div></article><section class="article labels"><a class="category" href=/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a><a class="tag" href=/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/>分类算法</a></section><section class="article navigation"><p><a class="link" href="/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A801/"><span class="li">&larr;</span>机器学习入门01</a></p><p><a class="link" href="/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A803/"><span class="li">&rarr;</span>机器学习入门03</a class="link">
    </p></section></div><section id="footer" class="footer">
    <script src="https://utteranc.es/client.js"
        repo="ChuWeiEr/hugoblogtalks"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><div class="footer-wrap">
    <p class="copyright">©2020 Notepadium.</p>
    <p class="powerby"><span>Powered by </span><a href="https://gohugo.io" 
        target="_blank">Hugo</a><span> and the </span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank">Notepadium</a></p>
</div></section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script></div>
</body>

</html>